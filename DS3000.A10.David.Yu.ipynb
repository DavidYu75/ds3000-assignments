{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 3000 - Assignment 10\n",
    "\n",
    "**Student Name**: David Yu\n",
    "\n",
    "**Date**: 3/19/25\n",
    "\n",
    "\n",
    "### Submission Instructions\n",
    "Submit this `ipynb` file to canvas.\n",
    "\n",
    "The `ipynb` format stores outputs from the last time you ran the notebook.  (When you open a notebook it has the figures and outputs of the last time you ran it too).  To ensure that your submitted `ipynb` file represents your latest code, make sure to give a fresh run `Kernel > Restart & Run All` just before uploading the `ipynb` file to Canvas.\n",
    "\n",
    "### Academic Integrity\n",
    "\n",
    "**Writing your homework is an individual effort.**  You may discuss general python problems with other students but under no circumstances should you observe another student's code which was written for this assignment, from this year or past years.  Pop into office hours or DM us in MS Teams if you have a specific question about your work or if you would like another pair of eyes or talk through your code.\n",
    "\n",
    "Don't forget to cite websites which helped you solve a problem in a unique way.  You can do this in markdown near the code or with a simple one-line comment. You do not need to cite the official python documentation.\n",
    "\n",
    "**Documentation / style counts for credit**  Please refer to the Pep-8 style, to improve the readability and consistency of your Python code. For more information, read the following article [How to Write Beautiful Python Code With PEP 8](https://realpython.com/python-pep8/) or ask your TA's for tips.\n",
    "\n",
    "**NOTE:<span style='color:red'> Write python expressions to answer ALL questions below and ensure that you use the `print()` function to display the output.</span>** Each question should be answered in a new code cell. For example, your solution for question 1.1 should be in a different code cell from your solution for question 1.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: \n",
    "\n",
    "load the data directly from the URL into a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   case  bwt  gestation  parity   age  height  weight  smoke\n",
      "0     1  120      284.0       0  27.0    62.0   100.0    0.0\n",
      "1     2  113      282.0       0  33.0    64.0   135.0    0.0\n",
      "2     3  128      279.0       0  28.0    64.0   115.0    1.0\n",
      "3     4  123        NaN       0  36.0    69.0   190.0    0.0\n",
      "4     5  108      282.0       0  23.0    67.0   125.0    1.0\n"
     ]
    }
   ],
   "source": [
    "url = \"https://drive.google.com/uc?id=145n4_o1g5ZMrnV_DZt8tR9rjZLlJvU5K\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: (10 pts) Data Prep & EDA\n",
    "Prepare the data for analysis. Ensure that you address the following:\n",
    "- Perform EDA using the dataset to demonstrate patterns.\n",
    "- Handle any missing data and invalid data. Justify your approach.\n",
    "- Plot a histogram of the birth weight and explain the overall distribution. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1236, 8)\n",
      "\n",
      "First 5 rows:\n",
      "   case  bwt  gestation  parity   age  height  weight  smoke\n",
      "0     1  120      284.0       0  27.0    62.0   100.0    0.0\n",
      "1     2  113      282.0       0  33.0    64.0   135.0    0.0\n",
      "2     3  128      279.0       0  28.0    64.0   115.0    1.0\n",
      "3     4  123        NaN       0  36.0    69.0   190.0    0.0\n",
      "4     5  108      282.0       0  23.0    67.0   125.0    1.0\n",
      "\n",
      "Missing values before cleaning:\n",
      "case          0\n",
      "bwt           0\n",
      "gestation    13\n",
      "parity        0\n",
      "age           2\n",
      "height       22\n",
      "weight       36\n",
      "smoke        10\n",
      "dtype: int64\n",
      "\n",
      "Missing values after NA conversion:\n",
      "case          0\n",
      "bwt           0\n",
      "gestation    13\n",
      "parity        0\n",
      "age           2\n",
      "height       22\n",
      "weight       36\n",
      "smoke        10\n",
      "dtype: int64\n",
      "\n",
      "Summary statistics:\n",
      "          case      bwt  gestation   parity      age   height   weight  \\\n",
      "count  1236.00  1236.00    1223.00  1236.00  1234.00  1214.00  1200.00   \n",
      "mean    618.50   119.58     279.34     0.25    27.26    64.05   128.63   \n",
      "std     356.95    18.24      16.03     0.44     5.78     2.53    20.97   \n",
      "min       1.00    55.00     148.00     0.00    15.00    53.00    87.00   \n",
      "25%     309.75   108.75     272.00     0.00    23.00    62.00   114.75   \n",
      "50%     618.50   120.00     280.00     0.00    26.00    64.00   125.00   \n",
      "75%     927.25   131.00     288.00     1.00    31.00    66.00   139.00   \n",
      "max    1236.00   176.00     353.00     1.00    45.00    72.00   250.00   \n",
      "\n",
      "         smoke  \n",
      "count  1226.00  \n",
      "mean      0.39  \n",
      "std       0.49  \n",
      "min       0.00  \n",
      "25%       0.00  \n",
      "50%       0.00  \n",
      "75%       1.00  \n",
      "max       1.00  \n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nMissing values before cleaning:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "df = df.replace(\"NA\", np.nan)\n",
    "\n",
    "# Convert all columns to appropriate data types\n",
    "for col in df.columns:\n",
    "    if col != 'case':\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "print(\"\\nMissing values after NA conversion:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after imputation:\n",
      "case         0\n",
      "bwt          0\n",
      "gestation    0\n",
      "parity       0\n",
      "age          0\n",
      "height       0\n",
      "weight       0\n",
      "smoke        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_clean = df.copy()\n",
    "\n",
    "# Impute missing values with median for each column\n",
    "for col in df_clean.columns:\n",
    "    if col != 'case' and df_clean[col].isna().sum() > 0:\n",
    "        median_val = df_clean[col].median()\n",
    "        df_clean[col] = df_clean[col].fillna(median_val)\n",
    "\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(df_clean.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing and Invalid Data\n",
    "1. Identifying missing values that were represented as \"NA\" strings as proper null values. I converted all them to NaN. This allows use to standardize our representation of missing values and it allows for proper handling by pandas.\n",
    "2. Imputing missing values with the median of each respective column. I chose to use medians because:\n",
    "- Medians are less likely to be affected by extreme outliers, unlike means.\n",
    "- Medians maintain the overall distribution shape of the data better than mode imputation.\n",
    "3. Using panda's pd.to_numeric() with errors='coerce' parameter for any potential invalid data types. This will convert any non-numeric values to NaN and ensures consistent data types across all feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Birth weight distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(df['bwt'].dropna(), bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Birth Weight')\n",
    "plt.xlabel('Birth Weight (ounces)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(df['bwt'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"bwt\"].mean():.2f}')\n",
    "plt.axvline(df['bwt'].median(), color='green', linestyle='--', label=f'Median: {df[\"bwt\"].median():.2f}')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Birth weights are approximately normally distributed. The mean of 119.58 ounces and the median of 120 ounces are very close to each other, showing that there is minimal skew.\n",
    "- Most babies have a weight of 100 - 140 ounces, which is typical healthy birht weight for babies.\n",
    "- Overall, this distribution reflects expected patterns of birth weights in a general population. There is no extremes or concerning outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: (5 pts) Feature Selection\n",
    "Demonstrate which features are useful to build the model. Briefly explain the reason for the features that you selected. Note: You can explore correlations, test hypothesis and/or other techniques. Remember that Data Science relies heavily on experimentation. Therefore, you are encouraged to experiment with your data.\n",
    "- Tip #1: ensure that you carefully consider each feature and share the pros and cons of your decisions.\n",
    "- Tip #2: you are predicting the birth weight, therefore it should not be one of your explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pearson Correlation Analysis: \n",
      "Correlations with birth weight:\n",
      " gestation: 0.4058\n",
      "    parity: -0.0461\n",
      "       age: 0.0337\n",
      "    height: 0.1973\n",
      "    weight: 0.1520\n",
      "     smoke: -0.2406\n",
      "\n",
      "Strongly correlated features (|r| > 0.3):\n",
      "parity ~ age: -0.3500\n",
      "height ~ weight: 0.4300\n",
      "\n",
      "F-regression Analysis: \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mF-regression Analysis: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Calculate F-statistics and p-values\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m f_values, p_values \u001b[38;5;241m=\u001b[39m f_regression(X, y)\n\u001b[1;32m     23\u001b[0m f_scores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(f_values, index\u001b[38;5;241m=\u001b[39mfeatures)\n\u001b[1;32m     24\u001b[0m p_values \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(p_values, index\u001b[38;5;241m=\u001b[39mfeatures)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:498\u001b[0m, in \u001b[0;36mf_regression\u001b[0;34m(X, y, center, force_finite)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    397\u001b[0m     {\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    404\u001b[0m )\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf_regression\u001b[39m(X, y, \u001b[38;5;241m*\u001b[39m, center\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, force_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    406\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Univariate linear regression tests returning F-statistic and p-values.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \n\u001b[1;32m    408\u001b[0m \u001b[38;5;124;03m    Quick linear model for testing the effect of a single regressor,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;124;03m    array([2.7..., 1.5..., 1.0...])\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 498\u001b[0m     correlation_coefficient \u001b[38;5;241m=\u001b[39m r_regression(\n\u001b[1;32m    499\u001b[0m         X, y, center\u001b[38;5;241m=\u001b[39mcenter, force_finite\u001b[38;5;241m=\u001b[39mforce_finite\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    501\u001b[0m     deg_of_freedom \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m center \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    503\u001b[0m     corr_coef_squared \u001b[38;5;241m=\u001b[39m correlation_coefficient\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:363\u001b[0m, in \u001b[0;36mr_regression\u001b[0;34m(X, y, center, force_finite)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    292\u001b[0m     {\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m )\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mr_regression\u001b[39m(X, y, \u001b[38;5;241m*\u001b[39m, center\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, force_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Pearson's r for each features and the target.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03m    Pearson's r is also known as the Pearson correlation coefficient.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    array([-0.15...,  1.        , -0.22...])\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    364\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;66;03m# Compute centered values\u001b[39;00m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;66;03m# Note that E[(x - mean(x))*(y - mean(y))] = E[x*(y - mean(y))], so we\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# need not center X\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     )\n\u001b[0;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1302\u001b[0m     X,\n\u001b[1;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   1304\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[1;32m   1305\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1306\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   1307\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   1308\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39mforce_writeable,\n\u001b[1;32m   1309\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m   1310\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m   1311\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[1;32m   1312\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[1;32m   1313\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[1;32m   1314\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1316\u001b[0m )\n\u001b[1;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1064\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1065\u001b[0m         array,\n\u001b[1;32m   1066\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1067\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1068\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1069\u001b[0m     )\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    124\u001b[0m     X,\n\u001b[1;32m    125\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[1;32m    126\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[1;32m    127\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[1;32m    128\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    129\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    130\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     )\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN."
     ]
    }
   ],
   "source": [
    "# Correlation Analysis\n",
    "print(\"\\nPearson Correlation Analysis: \")\n",
    "correlations = df_clean.drop('case', axis=1).corr()['bwt'].drop('bwt')\n",
    "abs_correlations = correlations.abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Correlations with birth weight:\")\n",
    "for feature, corr in correlations.items():\n",
    "    print(f\"{feature:>10}: {corr:.4f}\")\n",
    "\n",
    "# Feature Correlation\n",
    "print(\"\\nStrongly correlated features (|r| > 0.3):\")\n",
    "for i, feat1 in enumerate(features):\n",
    "    for j, feat2 in enumerate(features):\n",
    "        if i < j:\n",
    "            corr = correlation_matrix.loc[feat1, feat2]\n",
    "            if abs(corr) > 0.3:\n",
    "                print(f\"{feat1} ~ {feat2}: {corr:.4f}\")\n",
    "\n",
    "# F-regression Analysis\n",
    "print(\"\\nF-regression Analysis: \")\n",
    "# Calculate F-statistics and p-values\n",
    "f_values, p_values = f_regression(X, y)\n",
    "f_scores = pd.Series(f_values, index=features)\n",
    "p_values = pd.Series(p_values, index=features)\n",
    "\n",
    "# Combine scores and p-values\n",
    "feature_scores = pd.DataFrame({\n",
    "    'F_Score': f_scores,\n",
    "    'P_Value': p_values\n",
    "})\n",
    "feature_scores = feature_scores.sort_values('F_Score', ascending=False)\n",
    "\n",
    "print(\"F-statistics and p-values:\")\n",
    "print(feature_scores)\n",
    "\n",
    "# Statistical Tests for Categorical Variables\n",
    "print(\"\\nStatistical Tests for Categorical Variables: \")\n",
    "\n",
    "# Smoking\n",
    "smoker_bwt = df_clean[df_clean['smoke'] == 1]['bwt']\n",
    "nonsmoker_bwt = df_clean[df_clean['smoke'] == 0]['bwt']\n",
    "t_stat, p_val = stats.ttest_ind(nonsmoker_bwt, smoker_bwt, equal_var=False)\n",
    "print(f\"Smoking T-test: t={t_stat:.4f}, p={p_val:.8f}\")\n",
    "print(f\"Mean difference: {nonsmoker_bwt.mean() - smoker_bwt.mean():.2f} ounces\")\n",
    "\n",
    "# Parity\n",
    "first_bwt = df_clean[df_clean['parity'] == 0]['bwt']\n",
    "not_first_bwt = df_clean[df_clean['parity'] == 1]['bwt']\n",
    "t_stat, p_val = stats.ttest_ind(first_bwt, not_first_bwt, equal_var=False)\n",
    "print(f\"Parity T-test: t={t_stat:.4f}, p={p_val:.8f}\")\n",
    "print(f\"Mean difference: {not_first_bwt.mean() - first_bwt.mean():.2f} ounces\")\n",
    "\n",
    "# Incremental Feature Testing with Cross-Validation\n",
    "print(\"\\nCross-Validation Performance with Different Feature Sets:\")\n",
    "\n",
    "feature_sets = {\n",
    "    'gestation_only': ['gestation'],\n",
    "    'gestation_smoke': ['gestation', 'smoke'],\n",
    "    'gestation_smoke_height': ['gestation', 'smoke', 'height'],\n",
    "    'all_features': features\n",
    "}\n",
    "\n",
    "# Test each feature set with cross-validation\n",
    "cv_results = {}\n",
    "for name, feature_set in feature_sets.items():\n",
    "    model = LinearRegression()\n",
    "    X_subset = df_clean[feature_set]\n",
    "    \n",
    "    scores = cross_val_score(model, X_subset, y, cv=5, scoring='r2')\n",
    "    \n",
    "    cv_results[name] = {\n",
    "        'mean_r2': scores.mean(),\n",
    "        'std_r2': scores.std(),\n",
    "        'features': feature_set\n",
    "    }\n",
    "    \n",
    "    print(f\"{name}: Mean R^2 = {scores.mean():.4f} (±{scores.std():.4f})\")\n",
    "\n",
    "# Interaction Analysis (Smoking and Gestation)\n",
    "print(\"\\nPotential Interaction Effects: \")\n",
    "\n",
    "# Analyze interaction by fitting separate models for each group\n",
    "smokers = df_clean[df_clean['smoke'] == 1]\n",
    "nonsmokers = df_clean[df_clean['smoke'] == 0]\n",
    "\n",
    "# Fit linear regression for each group\n",
    "smoker_model = LinearRegression().fit(smokers[['gestation']], smokers['bwt'])\n",
    "nonsmoker_model = LinearRegression().fit(nonsmokers[['gestation']], nonsmokers['bwt'])\n",
    "\n",
    "print(\"Separate models by smoking status:\")\n",
    "print(f\"Non-smokers: bwt = {nonsmoker_model.intercept_:.2f} + {nonsmoker_model.coef_[0]:.4f} * gestation\")\n",
    "print(f\"Smokers: bwt = {smoker_model.intercept_:.2f} + {smoker_model.coef_[0]:.4f} * gestation\")\n",
    "\n",
    "# Plot interaction effect\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot points and regression lines\n",
    "plt.scatter(nonsmokers['gestation'], nonsmokers['bwt'], alpha=0.4, label='Non-smokers')\n",
    "plt.scatter(smokers['gestation'], smokers['bwt'], alpha=0.4, color='red', label='Smokers')\n",
    "\n",
    "# Create regression lines\n",
    "xrange = np.linspace(df_clean['gestation'].min(), df_clean['gestation'].max(), 100)\n",
    "plt.plot(xrange, nonsmoker_model.intercept_ + nonsmoker_model.coef_[0] * xrange, 'b-', \n",
    "         label=f'Non-smokers: y = {nonsmoker_model.intercept_:.2f} + {nonsmoker_model.coef_[0]:.2f}x')\n",
    "plt.plot(xrange, smoker_model.intercept_ + smoker_model.coef_[0] * xrange, 'r-', \n",
    "         label=f'Smokers: y = {smoker_model.intercept_:.2f} + {smoker_model.coef_[0]:.2f}x')\n",
    "\n",
    "plt.title('Gestation vs Birth Weight by Smoking Status')\n",
    "plt.xlabel('Gestation (days)')\n",
    "plt.ylabel('Birth Weight (ounces)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nFinal Feature Importance Summary: \")\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Correlation': [correlations[f] for f in features],\n",
    "    'Abs_Correlation': [abs(correlations[f]) for f in features],\n",
    "    'F_Score': [f_scores[f] for f in features],\n",
    "    'P_Value': [p_values[f] for f in features]\n",
    "})\n",
    "\n",
    "summary['Corr_Rank'] = summary['Abs_Correlation'].rank(ascending=False)\n",
    "summary['F_Rank'] = summary['F_Score'].rank(ascending=False)\n",
    "summary['Avg_Rank'] = (summary['Corr_Rank'] + summary['F_Rank']) / 2\n",
    "summary = summary.sort_values('Avg_Rank')\n",
    "\n",
    "print(summary[['Feature', 'Correlation', 'F_Score', 'P_Value', 'Avg_Rank']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestation Period\n",
    "### Pros:\n",
    "- Strongest correlation with birth weight with a value of 0.4\n",
    "- Highest F-score of 243.23 with an extremely significant p-value\n",
    "- Makes sense as longer pregnancies allow babies more time to develop and gain weight\n",
    "\n",
    "### Cons:\n",
    "- Some missing values in dataset\n",
    "- Can't be changed or modified once pregnancy has begun\n",
    "\n",
    "### Decision\n",
    "We are going to include this as the primary predictor because of its strong statistical relationship and clear biological basis.\n",
    "\n",
    "## Smoking Status\n",
    "### Pros:\n",
    "- Second strongest correlation of -0.24 and F-score of 75.84\n",
    "- Highly significant effect with a very small p-value\n",
    "- Adding smoking to gestation improves the R^2 value from 0.15 to 0.19\n",
    "\n",
    "### Cons:\n",
    "- Some missing values in dataset\n",
    "- Doesn't include the smoking intensity or duration\n",
    "- Self-reported data that may be unreliable\n",
    "\n",
    "### Decision:\n",
    "We are going to include smoking as a key predictor. There is a strong effect size and statistical significance.\n",
    "\n",
    "### Mother's Height\n",
    "### Pros:\n",
    "- Moderate correlation of 0.20 with a significant F-value of 49.96\n",
    "- Adding height to gestation and smoking improves R^2 to 0.22\n",
    "- Objective measurement with good reliablility\n",
    "\n",
    "### Cons:\n",
    "- Characteristic cannot be modified\n",
    "- Correlation with mother's weight (r=0.43) creates potential multicollinearity\n",
    "\n",
    "### Decision:\n",
    "We are going to include mother's height as it provides substantial predictive improvement and captures a distinct maternal characteristic.\n",
    "\n",
    "### Gestation and Smoking Interaction\n",
    "### Pros:\n",
    "- Captures the differential effects of gestation by smoking status\n",
    "- Regression coefficients show that smoking significantly modifies this relationship\n",
    "- Non-smokers: bwt = 19.8 + 0.3686 * gestation\n",
    "- Smokers: bwt = -51.32 + 0.5951 * gestation\n",
    "\n",
    "### Cons:\n",
    "- Requires both gestation and smoking to be reliable\n",
    "- Makes model more complex\n",
    "\n",
    "### Decision:\n",
    "We are going to include this because it captures the important complexity in how our key predictors interact with each other.\n",
    "\n",
    "## Mother's Weight\n",
    "### Pros:\n",
    "- Moderate correlation with 0.15 with signficant F-score of 29.18\n",
    "- Adding weight slightly improves model perfomance\n",
    "\n",
    "### Cons:\n",
    "- Significant multicollinearity with height, r=0.43\n",
    "- Current weight doesn't tell us as much as pre-pregnancy weight\n",
    "- Not a lot of improvement in R^2 when added to model\n",
    "\n",
    "### Decision:\n",
    "We are going to exclude weight as a standalone predictor. There is too much multicollinearity.\n",
    "\n",
    "## Parity\n",
    "### Pros:\n",
    "- No missing values\n",
    "- Binary variable\n",
    "- First babies do tend to be slightly smaller\n",
    "\n",
    "### Cons:\n",
    "- Weak correlation with a value of -0.05 and a low F-score of 2.63\n",
    "- Non-siginficant p-value of 0.105\n",
    "- T-tests show a marginal significance with a p=0.092\n",
    "\n",
    "### Decision:\n",
    "We are going to exlcude parity because of its weak statistical relationship. \n",
    "\n",
    "## Mother's Age\n",
    "### Pros:\n",
    "- Could have non-linear relationship with birth weight\n",
    "\n",
    "### Cons:\n",
    "- Weakest correlation of 0.03 and lowest F-score of 1.4\n",
    "- Non-significant p-value of 0.237\n",
    "\n",
    "### Decision:\n",
    "We are going to exclude mother's age because of its weak statistical relationship.\n",
    "\n",
    "## Final Features\n",
    "- Gestation\n",
    "- Smoking\n",
    "- Mother's height\n",
    "- Gestation and Smoking Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Data Partitioning\n",
    "(2 pts) Partition the prepared data into train/test sets, ensure that your partitions are reproducible. Encode any categorical variables in your training set. Then, use the appropriate approach to encode your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/Test split:\n",
      "X_train shape: (988, 4)\n",
      "X_test shape: (248, 4)\n",
      "y_train shape: (988,)\n",
      "y_test shape: (248,)\n",
      "\n",
      "After encoding:\n",
      "X_train_encoded shape: (988, 5)\n",
      "X_test_encoded shape: (248, 5)\n",
      "\n",
      "X_train_encoded columns:\n",
      "['gestation', 'height', 'gestation_x_smoke', 'smoke_1.0', 'smoke_nan']\n",
      "\n",
      "First 5 rows of X_train_encoded:\n",
      "      gestation  height  gestation_x_smoke  smoke_1.0  smoke_nan\n",
      "946       289.0    67.0              289.0        1.0        0.0\n",
      "394       313.0    59.0              313.0        1.0        0.0\n",
      "1023      287.0    62.0                0.0        0.0        0.0\n",
      "816       280.0    65.0              280.0        1.0        0.0\n",
      "88        305.0    70.0              305.0        1.0        0.0\n"
     ]
    }
   ],
   "source": [
    "df['gestation_x_smoke'] = df['gestation'] * df['smoke']\n",
    "\n",
    "# Define features and target based on our feature selection\n",
    "X = df[['gestation', 'smoke', 'height', 'gestation_x_smoke']]\n",
    "y = df['bwt']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nTrain/Test split:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "categorical_features = ['smoke']\n",
    "\n",
    "# Create OneHotEncoder for categorical features\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "if categorical_features:\n",
    "    encoder_fit = encoder.fit(X_train[categorical_features])\n",
    "    \n",
    "    encoded_train = encoder_fit.transform(X_train[categorical_features])\n",
    "    \n",
    "    encoded_feature_names = []\n",
    "    for i, feature in enumerate(categorical_features):\n",
    "        categories = encoder.categories_[i][1:] \n",
    "        for category in categories:\n",
    "            encoded_feature_names.append(f\"{feature}_{category}\")\n",
    "    \n",
    "    encoded_train_df = pd.DataFrame(\n",
    "        encoded_train, \n",
    "        columns=encoded_feature_names,\n",
    "        index=X_train.index\n",
    "    )\n",
    "    \n",
    "    X_train_encoded = X_train.drop(categorical_features, axis=1).join(encoded_train_df)\n",
    "    \n",
    "    encoded_test = encoder_fit.transform(X_test[categorical_features])\n",
    "    encoded_test_df = pd.DataFrame(\n",
    "        encoded_test, \n",
    "        columns=encoded_feature_names,\n",
    "        index=X_test.index\n",
    "    )\n",
    "    X_test_encoded = X_test.drop(categorical_features, axis=1).join(encoded_test_df)\n",
    "else:\n",
    "    X_train_encoded = X_train.copy()\n",
    "    X_test_encoded = X_test.copy()\n",
    "\n",
    "print(\"\\nAfter encoding:\")\n",
    "print(f\"X_train_encoded shape: {X_train_encoded.shape}\")\n",
    "print(f\"X_test_encoded shape: {X_test_encoded.shape}\")\n",
    "print(\"\\nX_train_encoded columns:\")\n",
    "print(X_train_encoded.columns.tolist())\n",
    "print(\"\\nFirst 5 rows of X_train_encoded:\")\n",
    "print(X_train_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Model Development\n",
    "(3 pts) Using the Random Forest algorithm, build a machine learning model that predicts the birth weight.\n",
    "Think about the following: Are you performing classification or regression? Ensure that you choose the appropriate Random Forest Classifier/Regressor from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor for birth weight prediction is built and trained.\n"
     ]
    }
   ],
   "source": [
    "df['gestation_x_smoke'] = df['gestation'] * df['smoke']\n",
    "\n",
    "X = df[['gestation', 'smoke', 'height', 'gestation_x_smoke']]\n",
    "y = df['bwt']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_features = ['smoke']\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "# Fit and transform training data\n",
    "if categorical_features:\n",
    "    encoder_fit = encoder.fit(X_train[categorical_features])\n",
    "    encoded_train = encoder_fit.transform(X_train[categorical_features])\n",
    "    \n",
    "    encoded_feature_names = []\n",
    "    for i, feature in enumerate(categorical_features):\n",
    "        categories = encoder.categories_[i][1:]\n",
    "        for category in categories:\n",
    "            encoded_feature_names.append(f\"{feature}_{category}\")\n",
    "    \n",
    "    \n",
    "    encoded_train_df = pd.DataFrame(\n",
    "        encoded_train, \n",
    "        columns=encoded_feature_names,\n",
    "        index=X_train.index\n",
    "    )\n",
    "    X_train_encoded = X_train.drop(categorical_features, axis=1).join(encoded_train_df)\n",
    "    \n",
    "    encoded_test = encoder_fit.transform(X_test[categorical_features])\n",
    "    encoded_test_df = pd.DataFrame(\n",
    "        encoded_test, \n",
    "        columns=encoded_feature_names,\n",
    "        index=X_test.index\n",
    "    )\n",
    "    X_test_encoded = X_test.drop(categorical_features, axis=1).join(encoded_test_df)\n",
    "else:\n",
    "    X_train_encoded = X_train.copy()\n",
    "    X_test_encoded = X_test.copy()\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train_encoded, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test_encoded)\n",
    "\n",
    "print(\"Random Forest Regressor for birth weight prediction is built and trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Random Forest Regressor because birth weight is continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: Model Evaluation\n",
    "(2 pts) Evaluate the predictions from your model and comment on the results. Ensure that you choose the appropriate metric to evaluate the model and round your calculations to two decimal places. Remember that we evaluate models differently depending on the task, i.e. classification or regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Model Evaluation:\n",
      "Mean Squared Error (MSE): 325.98\n",
      "Root Mean Squared Error (RMSE): 18.05\n",
      "Mean Absolute Error (MAE): 14.62\n",
      "R^2 Score: 0.17\n"
     ]
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse = round(mse, 2)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "rmse = math.sqrt(mse)\n",
    "rmse = round(rmse, 2)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mae = round(mae, 2)\n",
    "\n",
    "# R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "r2 = round(r2, 2)\n",
    "\n",
    "print(\"Random Forest Regression Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7: Model Tuning\n",
    "(10 pts) What are your thoughts on the model's prediction capability? Did it do a good job of predicting the birth weight? Justify your response.\n",
    "Note: it is okay if your first version of the model is not the best. However, there are strategies that we can use to improve it, such as tuning.\n",
    "- Tune the model: you can control the number of trees in your forest using the n_estimators parameter. Refer to the sample code from the lecture and also view the documentation**Links to an external site. to learn more about this algorithm and its parameters. Try at least 10 different values for the n_estimators parameter (excluding the default value) to determine if the model improved. Show all your steps to create, evaluate and tune each version of the model.\n",
    "- Indicate which model performed the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default model (n_estimators=100):\n",
      "RMSE: 18.05\n",
      "R^2: 0.17\n",
      "\n",
      "Tuning with different n_estimators values:\n",
      "n_estimators=10, RMSE=18.13, R^2=0.17\n",
      "n_estimators=50, RMSE=17.87, R^2=0.19\n",
      "n_estimators=150, RMSE=18.0, R^2=0.18\n",
      "n_estimators=200, RMSE=17.94, R^2=0.18\n",
      "n_estimators=250, RMSE=17.92, R^2=0.19\n",
      "n_estimators=300, RMSE=17.91, R^2=0.19\n",
      "n_estimators=350, RMSE=17.92, R^2=0.19\n",
      "n_estimators=400, RMSE=17.93, R^2=0.19\n",
      "n_estimators=450, RMSE=17.9, R^2=0.19\n",
      "n_estimators=500, RMSE=17.92, R^2=0.19\n",
      "\n",
      "Best model: n_estimators=50.0\n",
      "RMSE: 17.87\n",
      "R^2: 0.19\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = round(math.sqrt(mse), 2)\n",
    "    r2 = round(r2_score(y_test, y_pred), 2)\n",
    "    \n",
    "    return rmse, r2\n",
    "\n",
    "default_model = RandomForestRegressor(random_state=42)\n",
    "default_rmse, default_r2 = evaluate_model(default_model, X_train_encoded, X_test_encoded, y_train, y_test)\n",
    "\n",
    "print(f\"Default model (n_estimators=100):\")\n",
    "print(f\"RMSE: {default_rmse}\")\n",
    "print(f\"R^2: {default_r2}\")\n",
    "\n",
    "n_estimators_values = [10, 50, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "results = []\n",
    "\n",
    "print(\"\\nTuning with different n_estimators values:\")\n",
    "for n_est in n_estimators_values:\n",
    "    model = RandomForestRegressor(n_estimators=n_est, random_state=42)\n",
    "    rmse, r2 = evaluate_model(model, X_train_encoded, X_test_encoded, y_train, y_test)\n",
    "    \n",
    "    results.append({\n",
    "        'n_estimators': n_est,\n",
    "        'RMSE': rmse,\n",
    "        'R^2': r2\n",
    "    })\n",
    "    \n",
    "    print(f\"n_estimators={n_est}, RMSE={rmse}, R^2={r2}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "best_model = results_df.loc[results_df['RMSE'].idxmin()]\n",
    "print(f\"\\nBest model: n_estimators={best_model['n_estimators']}\")\n",
    "print(f\"RMSE: {best_model['RMSE']}\")\n",
    "print(f\"R^2: {best_model['R^2']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning the model, the best model used n_estimators=50 and had a RMSE of 17.87 ounces and a R^2 of 0.19. Overall, the model's prediciton capability isn't the best. The model's R^2 value of 0.19 means that only about 19% of the variance in birth weight can be explained by the model. This is a pretty low amount of explained variance, meaning there is still a lot of important factors in birth weight that are missing. Additionally, the RMSE of 17.87 ounces represents the typical prediction error. This is a pretty big prediction error, espeically given birth weight. Lastly, tuning the model with different n_estimators resulted in very small differences. The best model and the default model only had differences of 0.18 ounces in RMSE and 0.02 in R^2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful resources \n",
    "Don't forget to cite websites which helped you solve a problem in a unique way.  You can do this in markdown near the code or with a simple one-line comment inside the code cell, or you can list them below. \n",
    "\n",
    "You do not need to cite the official python documentation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
